{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":603,"status":"ok","timestamp":1675792902338,"user":{"displayName":"JABER RAHIMIFARD","userId":"09627694547151218378"},"user_tz":-60},"id":"-lAEtQJ4vxBE","outputId":"4db51d8a-74b0-4a3c-b1a8-f4e5fb6bae4c"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/AI_Project\n","\u001b[0m\u001b[01;34mCountPeople-14\u001b[0m/  index.ipynb  \u001b[01;34myolov5\u001b[0m/\n"]}],"source":["%cd drive/MyDrive/AI_Project/\n","%ls"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24735,"status":"ok","timestamp":1675792941446,"user":{"displayName":"JABER RAHIMIFARD","userId":"09627694547151218378"},"user_tz":-60},"id":"KFCxJ8Y3wKmY","outputId":"c9c4259f-fe40-48ed-eec5-b8bbf6b95647"},"outputs":[{"name":"stdout","output_type":"stream","text":["fatal: destination path 'yolov5' already exists and is not an empty directory.\n","/content/drive/MyDrive/AI_Project/yolov5\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.0/184.0 KB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 KB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m55.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.0/49.0 KB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 KB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 KB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["#clone YOLOv5 and \n","!git clone https://github.com/ultralytics/yolov5  # clone repo\n","%cd yolov5\n","%pip install -qr requirements.txt # install dependencies\n","%pip install -q roboflow"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2893,"status":"ok","timestamp":1675792947926,"user":{"displayName":"JABER RAHIMIFARD","userId":"09627694547151218378"},"user_tz":-60},"id":"mtmxa7F4wRly","outputId":"eb688388-a9c8-47fc-d0ca-9725c999f783"},"outputs":[{"name":"stdout","output_type":"stream","text":["Setup complete. Using torch 1.13.1+cu116 (Tesla T4)\n"]}],"source":["import torch\n","import os\n","from IPython.display import Image, clear_output  # to display images\n","print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1555,"status":"ok","timestamp":1675792951249,"user":{"displayName":"JABER RAHIMIFARD","userId":"09627694547151218378"},"user_tz":-60},"id":"WxV6cfGdwVms","outputId":"d446fdb4-354f-40ba-f781-b1157ff1c8b5"},"outputs":[{"name":"stdout","output_type":"stream","text":["upload and label your dataset, and get an API KEY here: https://app.roboflow.com/?model=yolov5\u0026ref=ultralytics\n"]}],"source":["from roboflow import Roboflow\n","rf = Roboflow(model_format=\"yolov5\", notebook=\"ultralytics\")"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":467,"status":"ok","timestamp":1675792953750,"user":{"displayName":"JABER RAHIMIFARD","userId":"09627694547151218378"},"user_tz":-60},"id":"NL_qtm3TwXy4"},"outputs":[],"source":["os.environ[\"DATASET_DIRECTORY\"] = \"/content/drive/MyDrive/AI_Project\""]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":820242,"status":"ok","timestamp":1675795756761,"user":{"displayName":"JABER RAHIMIFARD","userId":"09627694547151218378"},"user_tz":-60},"id":"t-GiiYLPwb7v","outputId":"82c67127-00df-4384-ff0a-c5dd76548942"},"outputs":[{"name":"stdout","output_type":"stream","text":["loading Roboflow workspace...\n","loading Roboflow project...\n","Downloading Dataset Version Zip in /content/drive/MyDrive/AI_Project/CountPeople-14 to yolov5pytorch: 100% [30275464 / 30275464] bytes\n"]},{"name":"stderr","output_type":"stream","text":["Extracting Dataset Version Zip to /content/drive/MyDrive/AI_Project/CountPeople-14 in yolov5pytorch:: 100%|██████████| 3424/3424 [37:48\u003c00:00,  1.51it/s]\n"]}],"source":["from roboflow import Roboflow\n","rf = Roboflow(api_key=\"6MZs0IEOrn1yaUepdoxH\")\n","project = rf.workspace(\"ca-foscari-university-of-venice\").project(\"countpeople\")\n","dataset = project.version(14).download(\"yolov5\")"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":529512,"status":"ok","timestamp":1675796291658,"user":{"displayName":"JABER RAHIMIFARD","userId":"09627694547151218378"},"user_tz":-60},"id":"ubzy8mZCwl1r","outputId":"d4b4f7b4-9b3f-4841-c2b9-a40d861f1f3a"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=/content/drive/MyDrive/AI_Project/CountPeople-14/data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=25, batch_size=16, imgsz=416, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n","Command 'git fetch origin' timed out after 5 seconds\n","YOLOv5 🚀 v7.0-74-gd02ee60 Python-3.8.10 torch-1.13.1+cu116 CUDA:0 (Tesla T4, 15110MiB)\n","\n","remote: Enumerating objects: 50, done.\u001b[K\n","remote: Counting objects: 100% (50/50), done.\u001b[K\n","remote: Compressing objects: 100% (33/33), done.\u001b[K\n","remote: Total 50 (delta 28), reused 35 (delta 17), pack-reused 0\u001b[K\n","\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n","\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n","\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n","Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n","100% 755k/755k [00:00\u003c00:00, 129MB/s]\n","Unpacking objects: 100% (50/50), 29.70 KiB | 9.00 KiB/s, done.\n","From https://github.com/ultralytics/yolov5\n","   d02ee60..c3c8e71  master     -\u003e origin/master\n"," * [new branch]      pre-commit-ci-update-config -\u003e origin/pre-commit-ci-update-config\n","   a770b2e..dc9fb88  v8_banner  -\u003e origin/v8_banner\n","Overriding model.yaml nc=80 with nc=1\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n","  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n","  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n","  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n","  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n","  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n","  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n","  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n","  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n","  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n"," 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n"," 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n"," 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n"," 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n"," 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n"," 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n"," 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n"," 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n"," 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n"," 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n"," 24      [17, 20, 23]  1     16182  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n","Model summary: 214 layers, 7022326 parameters, 7022326 gradients, 15.9 GFLOPs\n","\n","Transferred 343/349 items from yolov5s.pt\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/AI_Project/CountPeople-14/train/labels.cache... 1562 images, 0 backgrounds, 0 corrupt: 100% 1562/1562 [00:00\u003c?, ?it/s]\n","\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.6GB ram): 100% 1562/1562 [00:05\u003c00:00, 310.83it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/AI_Project/CountPeople-14/valid/labels.cache... 72 images, 0 backgrounds, 0 corrupt: 100% 72/72 [00:00\u003c?, ?it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB ram): 100% 72/72 [00:00\u003c00:00, 274.22it/s]\n","\n","\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.74 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n","Plotting labels to runs/train/exp/labels.jpg... \n","Image sizes 416 train, 416 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1mruns/train/exp\u001b[0m\n","Starting training for 25 epochs...\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       0/24      1.71G      0.079    0.02766          0         26        416: 100% 98/98 [00:19\u003c00:00,  4.97it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:01\u003c00:00,  1.82it/s]\n","                   all         72        106      0.611      0.638      0.682      0.296\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       1/24      1.91G    0.05002    0.02147          0         36        416: 100% 98/98 [00:17\u003c00:00,  5.53it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00\u003c00:00,  4.77it/s]\n","                   all         72        106      0.778      0.821       0.88       0.31\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       2/24      1.91G    0.04461    0.01904          0         26        416: 100% 98/98 [00:16\u003c00:00,  6.05it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00\u003c00:00,  6.86it/s]\n","                   all         72        106      0.519      0.755      0.633      0.375\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       3/24      1.91G    0.03931    0.01788          0         28        416: 100% 98/98 [00:16\u003c00:00,  6.11it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00\u003c00:00,  4.73it/s]\n","                   all         72        106      0.919      0.868      0.927      0.522\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       4/24      1.91G    0.03401    0.01692          0         33        416: 100% 98/98 [00:16\u003c00:00,  5.86it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00\u003c00:00,  6.59it/s]\n","                   all         72        106      0.937      0.877       0.95      0.673\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       5/24      1.91G    0.03192    0.01576          0         29        416: 100% 98/98 [00:16\u003c00:00,  5.91it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00\u003c00:00,  4.85it/s]\n","                   all         72        106      0.934      0.877      0.953      0.673\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       6/24      1.91G    0.02907    0.01542          0         40        416: 100% 98/98 [00:16\u003c00:00,  5.98it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00\u003c00:00,  7.00it/s]\n","                   all         72        106      0.939      0.868      0.945      0.573\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       7/24      1.91G    0.02767    0.01548          0         34        416: 100% 98/98 [00:15\u003c00:00,  6.19it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00\u003c00:00,  6.80it/s]\n","                   all         72        106      0.929      0.896      0.956      0.685\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       8/24      1.91G    0.02611    0.01447          0         22        416: 100% 98/98 [00:15\u003c00:00,  6.16it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00\u003c00:00,  6.78it/s]\n","                   all         72        106      0.946      0.849      0.935      0.662\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       9/24      1.91G    0.02626    0.01479          0         30        416: 100% 98/98 [00:15\u003c00:00,  6.16it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00\u003c00:00,  6.83it/s]\n","                   all         72        106      0.897      0.896      0.953      0.705\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      10/24      1.91G    0.02386    0.01409          0         29        416: 100% 98/98 [00:16\u003c00:00,  6.01it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00\u003c00:00,  4.96it/s]\n","                   all         72        106      0.948      0.868      0.948       0.69\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      11/24      1.91G    0.02322    0.01402          0         33        416: 100% 98/98 [00:17\u003c00:00,  5.76it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00\u003c00:00,  6.86it/s]\n","                   all         72        106       0.92      0.925      0.956      0.692\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      12/24      1.91G    0.02216    0.01373          0         31        416: 100% 98/98 [00:15\u003c00:00,  6.24it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00\u003c00:00,  6.84it/s]\n","                   all         72        106      0.956      0.858      0.932      0.703\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      13/24      1.91G    0.02202    0.01345          0         37        416: 100% 98/98 [00:15\u003c00:00,  6.19it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00\u003c00:00,  6.82it/s]\n","                   all         72        106      0.971       0.84      0.943      0.688\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      14/24      1.91G    0.02134    0.01324          0         29        416: 100% 98/98 [00:15\u003c00:00,  6.19it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00\u003c00:00,  6.85it/s]\n","                   all         72        106      0.958      0.866      0.931      0.684\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      15/24      1.91G    0.02075     0.0126          0         33        416: 100% 98/98 [00:15\u003c00:00,  6.13it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00\u003c00:00,  6.85it/s]\n","                   all         72        106      0.948      0.866      0.939      0.678\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      16/24      1.91G    0.01983    0.01267          0         36        416: 100% 98/98 [00:15\u003c00:00,  6.17it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00\u003c00:00,  5.03it/s]\n","                   all         72        106      0.939      0.874      0.934       0.71\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      17/24      1.91G    0.01979    0.01245          0         23        416: 100% 98/98 [00:16\u003c00:00,  5.85it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00\u003c00:00,  3.88it/s]\n","                   all         72        106      0.939      0.876      0.929      0.703\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      18/24      1.91G    0.01922     0.0121          0         36        416: 100% 98/98 [00:16\u003c00:00,  5.78it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00\u003c00:00,  6.98it/s]\n","                   all         72        106      0.948      0.864      0.937      0.711\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      19/24      1.91G    0.01903     0.0122          0         26        416: 100% 98/98 [00:15\u003c00:00,  6.22it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00\u003c00:00,  6.84it/s]\n","                   all         72        106       0.93      0.883      0.944      0.719\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      20/24      1.91G    0.01845    0.01206          0         35        416: 100% 98/98 [00:15\u003c00:00,  6.13it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00\u003c00:00,  7.02it/s]\n","                   all         72        106      0.946      0.858      0.945      0.727\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      21/24      1.91G    0.01822    0.01152          0         23        416: 100% 98/98 [00:15\u003c00:00,  6.15it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00\u003c00:00,  5.02it/s]\n","                   all         72        106      0.917      0.887      0.942      0.726\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      22/24      1.91G     0.0178    0.01151          0         29        416: 100% 98/98 [00:16\u003c00:00,  5.94it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00\u003c00:00,  5.07it/s]\n","                   all         72        106      0.964      0.849      0.939      0.721\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      23/24      1.91G    0.01706    0.01119          0         28        416: 100% 98/98 [00:15\u003c00:00,  6.22it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00\u003c00:00,  6.98it/s]\n","                   all         72        106      0.919      0.896      0.944      0.722\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      24/24      1.91G    0.01685    0.01079          0         40        416: 100% 98/98 [00:15\u003c00:00,  6.26it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00\u003c00:00,  6.89it/s]\n","                   all         72        106      0.958      0.867      0.938      0.729\n","\n","25 epochs completed in 0.122 hours.\n","Optimizer stripped from runs/train/exp/weights/last.pt, 14.3MB\n","Optimizer stripped from runs/train/exp/weights/best.pt, 14.3MB\n","\n","Validating runs/train/exp/weights/best.pt...\n","Fusing layers... \n","Model summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:01\u003c00:00,  2.55it/s]\n","                   all         72        106      0.958      0.867      0.938       0.73\n","Results saved to \u001b[1mruns/train/exp\u001b[0m\n"]}],"source":["!python train.py --img 416 --batch 16 --epochs 25 --data {'/content/drive/MyDrive/AI_Project/CountPeople-14'}/data.yaml --weights yolov5s.pt --cache"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":103978,"status":"ok","timestamp":1675796412710,"user":{"displayName":"JABER RAHIMIFARD","userId":"09627694547151218378"},"user_tz":-60},"id":"sixTDwKOxz2e","outputId":"5cbb6cca-daec-4e72-f317-ddfff41c2bae"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/drive/MyDrive/AI_Project/yolov5/runs/train/exp/weights/best.pt'], source=/content/drive/MyDrive/Pellilo/Main/CountPeople-14/test/images, data=data/coco128.yaml, imgsz=[416, 416], conf_thres=0.7, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n","YOLOv5 🚀 v7.0-74-gd02ee60 Python-3.8.10 torch-1.13.1+cu116 CUDA:0 (Tesla T4, 15110MiB)\n","\n","Fusing layers... \n","Model summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n","image 1/72 /content/drive/MyDrive/Pellilo/Main/CountPeople-14/test/images/2015_05_09_14_40_16FrontColor_mp4-1_jpg.rf.4378ce8f3253925a4631b126ce1375a9.jpg: 320x416 2 Peoples, 12.9ms\n","image 2/72 /content/drive/MyDrive/Pellilo/Main/CountPeople-14/test/images/2015_05_09_14_46_27FrontColor_mp4-5_jpg.rf.63935ed7018aa45aaa7abfda3051ba1c.jpg: 320x416 1 People, 9.4ms\n","image 3/72 /content/drive/MyDrive/Pellilo/Main/CountPeople-14/test/images/2015_05_09_14_57_42FrontColor_mp4-1_jpg.rf.3a40ca82980e0cf41636c6245e9b103a.jpg: 320x416 1 People, 10.6ms\n","image 4/72 /content/drive/MyDrive/Pellilo/Main/CountPeople-14/test/images/2015_05_09_14_57_42FrontColor_mp4-2_jpg.rf.e77c4d712d2a313216cbd0d3a6b2247d.jpg: 320x416 1 People, 12.6ms\n","image 5/72 /content/drive/MyDrive/Pellilo/Main/CountPeople-14/test/images/2015_05_09_14_57_42FrontColor_mp4-4_jpg.rf.c0cb01b58012c9158df385be68dc0285.jpg: 320x416 1 People, 8.6ms\n","image 6/72 /content/drive/MyDrive/Pellilo/Main/CountPeople-14/test/images/2015_05_09_15_12_50FrontColor_mp4-0_jpg.rf.d2627ee6e32080ea778ef4c9e7e98bde.jpg: 320x416 1 People, 8.5ms\n","image 7/72 /content/drive/MyDrive/Pellilo/Main/CountPeople-14/test/images/2015_05_09_15_12_50FrontColor_mp4-1_jpg.rf.fee3c47983d9d4de0801a8d02dd77b6a.jpg: 320x416 1 People, 9.0ms\n","image 8/72 /content/drive/MyDrive/Pellilo/Main/CountPeople-14/test/images/2015_05_09_15_12_50FrontColor_mp4-2_jpg.rf.5eae424021ef7a5a96c5d6943d537c2c.jpg: 320x416 1 People, 9.9ms\n","image 9/72 /content/drive/MyDrive/Pellilo/Main/CountPeople-14/test/images/2015_05_09_15_12_50FrontColor_mp4-3_jpg.rf.5ea649a9a170578b70835916ce7db6d6.jpg: 320x416 2 Peoples, 9.0ms\n","image 10/72 /content/drive/MyDrive/Pellilo/Main/CountPeople-14/test/images/2015_05_09_15_12_50FrontColor_mp4-4_jpg.rf.5fbe11131e4fd59b084682a95da79358.jpg: 320x416 2 Peoples, 8.9ms\n","image 11/72 /content/drive/MyDrive/Pellilo/Main/CountPeople-14/test/images/2015_05_09_15_12_50FrontColor_mp4-5_jpg.rf.fccd2558bb411dfe6dd61b974db47a8b.jpg: 320x416 2 Peoples, 8.7ms\n","image 12/72 /content/drive/MyDrive/Pellilo/Main/CountPeople-14/test/images/2015_05_09_15_12_50FrontColor_mp4-6_jpg.rf.35273cc938b558d42a7b364e310931f8.jpg: 320x416 1 People, 8.7ms\n","image 13/72 /content/drive/MyDrive/Pellilo/Main/CountPeople-14/test/images/2015_05_09_15_12_50FrontColor_mp4-7_jpg.rf.b7c5414af16c95d34f421f9ece55964e.jpg: 320x416 1 People, 12.1ms\n","image 14/72 /content/drive/MyDrive/Pellilo/Main/CountPeople-14/test/images/2015_05_09_15_59_50FrontColor_mp4-0_jpg.rf.0aea2cd7782f4a843e822ab5832c846c.jpg: 320x416 3 Peoples, 14.6ms\n","image 15/72 /content/drive/MyDrive/Pellilo/Main/CountPeople-14/test/images/2015_05_09_15_59_50FrontColor_mp4-10_jpg.rf.78c6754c5adaa908eab1d311737d6eee.jpg: 320x416 1 People, 8.5ms\n","image 16/72 /content/drive/MyDrive/Pellilo/Main/CountPeople-14/test/images/2015_05_09_15_59_50FrontColor_mp4-11_jpg.rf.3949ce249cb29c245b70b75c74b898da.jpg: 320x416 1 People, 9.8ms\n","image 17/72 /content/drive/MyDrive/Pellilo/Main/CountPeople-14/test/images/2015_05_09_15_59_50FrontColor_mp4-12_jpg.rf.c761ffda9266b1533590d489ab070983.jpg: 320x416 1 People, 9.8ms\n","image 18/72 /content/drive/MyDrive/Pellilo/Main/CountPeople-14/test/images/2015_05_09_15_59_50FrontColor_mp4-13_jpg.rf.6d5fa2a4051235efaaaf83aff63bda60.jpg: 320x416 1 People, 8.8ms\n","image 19/72 /content/drive/MyDrive/Pellilo/Main/CountPeople-14/test/images/2015_05_09_15_59_50FrontColor_mp4-14_jpg.rf.be54f55becb67dec256980757189fe4c.jpg: 320x416 (no detections), 8.5ms\n","image 20/72 /content/drive/MyDrive/Pellilo/Main/CountPeople-14/test/images/2015_05_09_15_59_50FrontColor_mp4-1_jpg.rf.cc7af229c93d18a7ce4c8fbde4efb869.jpg: 320x416 3 Peoples, 8.4ms\n","image 21/72 /content/drive/MyDrive/Pellilo/Main/CountPeople-14/test/images/2015_05_09_15_59_50FrontColor_mp4-2_jpg.rf.9cd3a9fe00d012cb2fdbd1099ab513a8.jpg: 320x416 3 Peoples, 9.9ms\n","image 22/72 /content/drive/MyDrive/Pellilo/Main/CountPeople-14/test/images/2015_05_09_15_59_50FrontColor_mp4-3_jpg.rf.dc23587ad4400305d0ee13d9c9202593.jpg: 320x416 3 Peoples, 9.5ms\n","image 23/72 /content/drive/MyDrive/Pellilo/Main/CountPeople-14/test/images/2015_05_09_15_59_50FrontColor_mp4-4_jpg.rf.ce33871f4334005420b13425785ba780.jpg: 320x416 2 Peoples, 14.2ms\n","image 24/72 /content/drive/MyDrive/Pellilo/Main/CountPeople-14/test/images/2015_05_09_15_59_50FrontColor_mp4-5_jpg.rf.31003de2f385b21f3874d57f28a2ade8.jpg: 320x416 2 Peoples, 14.0ms\n","image 25/72 /content/drive/MyDrive/Pellilo/Main/CountPeople-14/test/images/2015_05_09_15_59_50FrontColor_mp4-6_jpg.rf.849ee8c180dc20c198a78c4ef4bcf8e3.jpg: 320x416 1 People, 9.0ms\n","image 26/72 /content/drive/MyDrive/Pellilo/Main/CountPeople-14/test/images/2015_05_09_15_59_50FrontColor_mp4-7_jpg.rf.99713b435254a6d73cc59c6d49010550.jpg: 320x416 2 Peoples, 8.6ms\n","image 27/72 /content/drive/MyDrive/Pellilo/Main/CountPeople-14/test/images/2015_05_09_15_59_50FrontColor_mp4-8_jpg.rf.651578837b16746991523be660e62107.jpg: 320x416 2 Peoples, 9.0ms\n","image 28/72 /content/drive/MyDrive/Pellilo/Main/CountPeople-14/test/images/2015_05_09_15_59_50FrontColor_mp4-9_jpg.rf.38f3fd099f163ebd4fea53c0624213b5.jpg: 320x416 1 People, 10.5ms\n","image 29/72 /content/drive/MyDrive/Pellilo/Main/CountPeople-14/test/images/2015_05_09_16_26_09FrontColor_mp4-2_jpg.rf.15171e890de7b7d04b2a772b808c5c70.jpg: 320x416 1 People, 8.6ms\n","image 30/72 /content/drive/MyDrive/Pellilo/Main/CountPeople-14/test/images/2015_05_09_16_54_14FrontColor_mp4-10_jpg.rf.d02d0c63eeb57af1a2722ffe0a89df6b.jpg: 320x416 1 People, 9.0ms\n","image 31/72 /content/drive/MyDrive/Pellilo/Main/CountPeople-14/test/images/2015_05_09_16_54_14FrontColor_mp4-2_jpg.rf.2025dcf2e820e04942cefa70d12d6c0f.jpg: 320x416 1 People, 8.5ms\n","image 32/72 /content/drive/MyDrive/Pellilo/Main/CountPeople-14/test/images/2015_05_09_16_54_14FrontColor_mp4-3_jpg.rf.8b42022141592d992cdbeae48eaccd93.jpg: 320x416 1 People, 14.1ms\n","image 33/72 /content/drive/MyDrive/Pellilo/Main/CountPeople-14/test/images/2015_05_09_17_29_59FrontColor_mp4-0_jpg.rf.c1c67fc00082cedfefe9934b4bb1fb75.jpg: 320x416 1 People, 11.5ms\n","image 34/72 /content/drive/MyDrive/Pellilo/Main/CountPeople-14/test/images/2015_05_09_17_29_59FrontColor_mp4-1_jpg.rf.79e1287cf15027a6b8fe097f49f18f43.jpg: 320x416 1 People, 9.2ms\n","image 35/72 /content/drive/MyDrive/Pellilo/Main/CountPeople-14/test/images/2015_05_09_17_29_59FrontColor_mp4-5_jpg.rf.81f8444e8452de16f2627be2c9101d4a.jpg: 320x416 1 People, 9.0ms\n","image 36/72 /content/drive/MyDrive/Pellilo/Main/CountPeople-14/test/images/2015_05_09_17_29_59FrontColor_mp4-6_jpg.rf.bee05f65bc702267ab5e958ba135852f.jpg: 320x416 1 People, 14.8ms\n","image 37/72 /content/drive/MyDrive/Pellilo/Main/CountPeople-14/test/images/2015_05_09_17_29_59FrontColor_mp4-7_jpg.rf.9f2353bbf6b6df063e275ea642a2cb38.jpg: 320x416 1 People, 9.6ms\n","image 38/72 /content/drive/MyDrive/Pellilo/Main/CountPeople-14/test/images/2015_05_09_17_29_59FrontColor_mp4-8_jpg.rf.5a80800f29a93c13d11485bd49fa5a82.jpg: 320x416 1 People, 10.7ms\n","image 39/72 /content/drive/MyDrive/Pellilo/Main/CountPeople-14/test/images/2015_05_09_17_47_12FrontColor_mp4-1_jpg.rf.dea2300195e01d849be5b055c92099ac.jpg: 320x416 1 People, 9.7ms\n","image 40/72 /content/drive/MyDrive/Pellilo/Main/CountPeople-14/test/images/2015_05_09_17_47_12FrontColor_mp4-2_jpg.rf.c36fef7b2292898d83a61555e904a220.jpg: 320x416 1 People, 8.4ms\n","image 41/72 /content/drive/MyDrive/Pellilo/Main/CountPeople-14/test/images/2015_05_09_17_47_12FrontColor_mp4-3_jpg.rf.65e110e6b89149242426611dd198fdf1.jpg: 320x416 1 People, 9.7ms\n","image 42/72 /content/drive/MyDrive/Pellilo/Main/CountPeople-14/test/images/2015_05_09_17_47_12FrontColor_mp4-4_jpg.rf.aa5d4cb7eab6029c1caf118d6f423110.jpg: 320x416 1 People, 12.0ms\n","image 43/72 /content/drive/MyDrive/Pellilo/Main/CountPeople-14/test/images/2015_05_09_17_47_12FrontColor_mp4-8_jpg.rf.42e5fbe721a0411a542b8102a11eaab0.jpg: 320x416 1 People, 11.5ms\n","image 44/72 /content/drive/MyDrive/Pellilo/Main/CountPeople-14/test/images/2015_05_09_17_47_12FrontColor_mp4-9_jpg.rf.137e99bc99de8f48ffbb1c0dad53c5f4.jpg: 320x416 1 People, 9.6ms\n","image 45/72 /content/drive/MyDrive/Pellilo/Main/CountPeople-14/test/images/2015_05_09_17_54_41FrontColor_mp4-11_jpg.rf.63a89129ee9fa0518e9e02f207a9eead.jpg: 320x416 1 People, 8.5ms\n","image 46/72 /content/drive/MyDrive/Pellilo/Main/CountPeople-14/test/images/2015_05_09_17_54_41FrontColor_mp4-12_jpg.rf.ec5d933687db460a548744574dab77bd.jpg: 320x416 1 People, 8.9ms\n","image 47/72 /content/drive/MyDrive/Pellilo/Main/CountPeople-14/test/images/2015_05_09_17_54_41FrontColor_mp4-3_jpg.rf.70ba9776fd7acfc457895a2e63122cd7.jpg: 320x416 1 People, 8.6ms\n","image 48/72 /content/drive/MyDrive/Pellilo/Main/CountPeople-14/test/images/2015_05_09_17_54_41FrontColor_mp4-7_jpg.rf.0aeef38e92224588dc7184cd76a7f60c.jpg: 320x416 1 People, 8.6ms\n","image 49/72 /content/drive/MyDrive/Pellilo/Main/CountPeople-14/test/images/2015_05_09_17_54_41FrontColor_mp4-9_jpg.rf.dc9d0a280c70c7bf8c172ef01e604992.jpg: 320x416 1 People, 10.7ms\n","image 50/72 /content/drive/MyDrive/Pellilo/Main/CountPeople-14/test/images/2015_05_09_18_08_48FrontColor_mp4-10_jpg.rf.d79bddd4460ae57dbf023e20bc20dd84.jpg: 320x416 2 Peoples, 9.1ms\n","image 51/72 /content/drive/MyDrive/Pellilo/Main/CountPeople-14/test/images/2015_05_09_18_08_48FrontColor_mp4-11_jpg.rf.7a56f20dace19119c13a148edcf3dccb.jpg: 320x416 1 People, 13.3ms\n","image 52/72 /content/drive/MyDrive/Pellilo/Main/CountPeople-14/test/images/2015_05_09_18_08_48FrontColor_mp4-12_jpg.rf.29498980d977ad27d0ed849fca39dd24.jpg: 320x416 1 People, 11.5ms\n","image 53/72 /content/drive/MyDrive/Pellilo/Main/CountPeople-14/test/images/2015_05_09_18_08_48FrontColor_mp4-15_jpg.rf.604489c05ce37dfcf83a29cfac7840ad.jpg: 320x416 1 People, 8.8ms\n","image 54/72 /content/drive/MyDrive/Pellilo/Main/CountPeople-14/test/images/2015_05_09_18_08_48FrontColor_mp4-16_jpg.rf.e8959121e64279b2efa9cc8e4a2be9e5.jpg: 320x416 1 People, 8.7ms\n","image 55/72 /content/drive/MyDrive/Pellilo/Main/CountPeople-14/test/images/2015_05_09_18_08_48FrontColor_mp4-1_jpg.rf.13af9b95c45d0961274fd6d07e4e09b5.jpg: 320x416 (no detections), 8.5ms\n","image 56/72 /content/drive/MyDrive/Pellilo/Main/CountPeople-14/test/images/2015_05_09_18_08_48FrontColor_mp4-2_jpg.rf.69713d2b88d8271be1dceca028a83389.jpg: 320x416 2 Peoples, 8.6ms\n","image 57/72 /content/drive/MyDrive/Pellilo/Main/CountPeople-14/test/images/2015_05_09_18_08_48FrontColor_mp4-3_jpg.rf.c3312b04ae6ddcd5122da105c7dd1163.jpg: 320x416 2 Peoples, 11.9ms\n","image 58/72 /content/drive/MyDrive/Pellilo/Main/CountPeople-14/test/images/2015_05_09_18_08_48FrontColor_mp4-4_jpg.rf.a3b891c2b61f76b8678ee264db784dcd.jpg: 320x416 2 Peoples, 14.9ms\n","image 59/72 /content/drive/MyDrive/Pellilo/Main/CountPeople-14/test/images/2015_05_09_18_08_48FrontColor_mp4-5_jpg.rf.c6ceab6ffeea27c08899535ff97c9712.jpg: 320x416 1 People, 8.5ms\n","image 60/72 /content/drive/MyDrive/Pellilo/Main/CountPeople-14/test/images/2015_05_09_18_08_48FrontColor_mp4-6_jpg.rf.7a27fab538d973025ad7552a1bbb64a6.jpg: 320x416 2 Peoples, 8.8ms\n","image 61/72 /content/drive/MyDrive/Pellilo/Main/CountPeople-14/test/images/2015_05_09_18_08_48FrontColor_mp4-7_jpg.rf.2f5f2c02ed907641899fe512eeb81b29.jpg: 320x416 1 People, 8.8ms\n","image 62/72 /content/drive/MyDrive/Pellilo/Main/CountPeople-14/test/images/2015_05_09_18_08_48FrontColor_mp4-8_jpg.rf.49fadc39479dced32cca97afa792aac2.jpg: 320x416 2 Peoples, 12.6ms\n","image 63/72 /content/drive/MyDrive/Pellilo/Main/CountPeople-14/test/images/2015_05_09_18_08_48FrontColor_mp4-9_jpg.rf.f1e0c83b445b31893711367c5d15af95.jpg: 320x416 2 Peoples, 11.7ms\n","image 64/72 /content/drive/MyDrive/Pellilo/Main/CountPeople-14/test/images/2015_05_09_18_57_38FrontColor_mp4-0_jpg.rf.8ce8538a28905c4a3194c41cd0f9920c.jpg: 320x416 1 People, 8.7ms\n","image 65/72 /content/drive/MyDrive/Pellilo/Main/CountPeople-14/test/images/2015_05_09_18_57_38FrontColor_mp4-1_jpg.rf.da2c41c5779f8657013e6d76d17124a9.jpg: 320x416 1 People, 9.0ms\n","image 66/72 /content/drive/MyDrive/Pellilo/Main/CountPeople-14/test/images/2015_05_09_18_57_38FrontColor_mp4-2_jpg.rf.8e6cb13557b3f7264b4a35a36e445dc6.jpg: 320x416 1 People, 8.9ms\n","image 67/72 /content/drive/MyDrive/Pellilo/Main/CountPeople-14/test/images/2015_05_09_19_41_53FrontColor_mp4-3_jpg.rf.2a65f01c828c5d30120a3970c7e7a62f.jpg: 320x416 2 Peoples, 9.0ms\n","image 68/72 /content/drive/MyDrive/Pellilo/Main/CountPeople-14/test/images/2015_05_09_19_41_53FrontColor_mp4-5_jpg.rf.26190af790b78efdfa71975398eaefa5.jpg: 320x416 1 People, 8.7ms\n","image 69/72 /content/drive/MyDrive/Pellilo/Main/CountPeople-14/test/images/2015_05_09_19_41_53FrontColor_mp4-6_jpg.rf.abc50bc94305c194cc5e110d51889be5.jpg: 320x416 1 People, 8.7ms\n","image 70/72 /content/drive/MyDrive/Pellilo/Main/CountPeople-14/test/images/2015_05_09_19_41_53FrontColor_mp4-7_jpg.rf.1ffa79331a5f2988ae2dae7fd4728b4e.jpg: 320x416 2 Peoples, 8.7ms\n","image 71/72 /content/drive/MyDrive/Pellilo/Main/CountPeople-14/test/images/2015_05_09_19_41_53FrontColor_mp4-8_jpg.rf.ce3ae606ada5e129c4b92b8ef587933b.jpg: 320x416 2 Peoples, 9.1ms\n","image 72/72 /content/drive/MyDrive/Pellilo/Main/CountPeople-14/test/images/2015_05_09_19_56_27FrontColor_mp4-0_jpg.rf.4f682a875800fadd9b2e9648a74e16ce.jpg: 320x416 1 People, 11.9ms\n","Speed: 0.4ms pre-process, 10.0ms inference, 1.1ms NMS per image at shape (1, 3, 416, 416)\n","Results saved to \u001b[1mruns/detect/exp\u001b[0m\n"]}],"source":["!python /content/drive/MyDrive/AI_Project/yolov5/detect.py --weights /content/drive/MyDrive/AI_Project/yolov5/runs/train/exp/weights/best.pt --img 416 --conf 0.7 --source {'/content/drive/MyDrive/Pellilo/Main/CountPeople-14'}/test/images\n"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"14qvFHgYrh4DBMBVAebaBtr1G3VXBtWq9"},"executionInfo":{"elapsed":24439,"status":"ok","timestamp":1675796485421,"user":{"displayName":"JABER RAHIMIFARD","userId":"09627694547151218378"},"user_tz":-60},"id":"g_to7Yye0tsh","outputId":"2fd69b34-3a1e-4172-b261-1c6e2b61b915"},"outputs":[],"source":["import cv2 as cv\n","import glob\n","import torch\n","import pandas as pd\n","import numpy as np\n","\n","data = []\n","model = torch.hub.load('/content/drive/MyDrive/AI_Project/yolov5','custom', path='/content/drive/MyDrive/AI_Project/yolov5/runs/train/exp/weights/best.pt', source='local')\n","\n","files = glob.glob(\"/content/drive/MyDrive/AI_Project/yolov5/runs/detect/exp/*.jpg\")\n","\n","for myFile in files:\n","    img = cv.imread(myFile)\n","    \n","    results = model(img)\n","    #results.print() \n","    display(Image(filename=myFile))\n","    data.append(results)\n","\n","df = pd.DataFrame(data)\n","\n","    "]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":1055,"status":"ok","timestamp":1675796493110,"user":{"displayName":"JABER RAHIMIFARD","userId":"09627694547151218378"},"user_tz":-60},"id":"NWTizJ_p1iRw"},"outputs":[],"source":["df.to_csv(\"df.csv\", index=False)"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1675796495147,"user":{"displayName":"JABER RAHIMIFARD","userId":"09627694547151218378"},"user_tz":-60},"id":"gRkm0qtE1Id6"},"outputs":[],"source":["# Load the csv file into a pandas dataframe\n","df = pd.read_csv('df.csv')\n","\n","# Split the strings in each cell into a list of strings\n","split_strings = df[df.columns[0]].apply(lambda x: x.split(\" \"))\n","\n","# Convert the list of strings into a dataframe\n","result = pd.DataFrame(split_strings.tolist(), columns=[f\"Column {i}\" for i in range(1, len(max(split_strings, key=len)) + 1)])"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":527,"status":"ok","timestamp":1675796497600,"user":{"displayName":"JABER RAHIMIFARD","userId":"09627694547151218378"},"user_tz":-60},"id":"ABkFH2n61nae"},"outputs":[],"source":["result.columns = ['Column_1', 'Column_2','Column_3', 'Column_4','Column_5', 'Column_6','Column_7', 'Column_8','Column_9', 'Column_10','Column_11', 'Column_12','Column_13', 'Column_14','Column_15', 'Column_16','Column_17', 'Column_18','Column_19']"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1675796499837,"user":{"displayName":"JABER RAHIMIFARD","userId":"09627694547151218378"},"user_tz":-60},"id":"DbhOtrJs1u2w","outputId":"449e048c-4a49-4d32-b9c0-111457a77420"},"outputs":[{"name":"stdout","output_type":"stream","text":["Total number of peoples in the all images is: 115.0\n"]}],"source":["result['Column_4'] = pd.to_numeric(result['Column_4'], errors='coerce')\n","People = result['Column_4'].sum()\n","\n","print(\"Total number of peoples in the all images is:\", People)"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyMZs32v3pjnop20MELBy9ao","mount_file_id":"10cv9boBb_bfjkQ13MwD6zxloQHRugCQX","name":"","version":""},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}